{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config, pubsub, database\n",
    "import os, json, csv\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions  import date_format\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# the pubsub subscription message queue is stored in the memory and\n",
    "# when processing request comes in, it is consumed and written to\n",
    "# a temp file.\n",
    "# in the demo no synch mechanism is used, assuming only one\n",
    "# request is process at any time.\n",
    "_TEMP_FILE_NAME = 'aggregator_dummy.csv'\n",
    "\n",
    "def write_rows_to_database(column_family_id, rows):\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "        database.write_transaction(column_family_id, row['timestamp'], row['user_id'], row['spend'])\n",
    "\n",
    "def _consume_subscription_queue(subscription_id):\n",
    "    with open(_TEMP_FILE_NAME, 'w') as outf:\n",
    "        csv_writer = csv.writer(outf, delimiter=',',\n",
    "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        process.header_written = False\n",
    "        def on_msg(msg):\n",
    "            print('msg: {}'.format(msg.decode()))\n",
    "            js = json.loads(msg.decode())\n",
    "            if not process.header_written:\n",
    "                csv_writer.writerow(js.keys())\n",
    "                process.header_written = True\n",
    "            csv_writer.writerow(js.values())\n",
    "\n",
    "        pubsub.listen_to_subscription(subscription_id, on_msg)\n",
    "\n",
    "def _aggregate(from_timestamp, to_timestamp):\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Data cleaning\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "        .load(_TEMP_FILE_NAME)\n",
    "\n",
    "    # TODO: try to load with filters\n",
    "    df = df.filter((df.timestamp > from_timestamp) & (df.timestamp < to_timestamp))\n",
    "\n",
    "    # aggregate by hour to show the timeline of the spending per hour.\n",
    "    df_truncate_by_hour = df.withColumn('timestamp', (df.timestamp / 3600).cast('int') * 3600)\n",
    "    sum_by_hour_by_user_id = df_truncate_by_hour \\\n",
    "        .groupby(df_truncate_by_hour.user_id, df_truncate_by_hour.timestamp)\\\n",
    "        .agg({\"spend\": \"sum\"})\\\n",
    "        .withColumnRenamed('sum(spend)', 'spend')\\\n",
    "        .collect()\n",
    "\n",
    "    # for the sum over the time range, add the timestamp @ the end boundary of the time range.\n",
    "    # the sum is aggregated over the per-minute calculation, thus to avoid doing the minute level\n",
    "    # aggregation again, would boost the speed when the volume is high.\n",
    "    sum_by_user_id =  df_truncate_by_minute.groupby(df_truncate_by_minute.user_id)\\\n",
    "        .agg({\"spend\": \"sum\"})\\\n",
    "        .withColumnRenamed('sum(spend)', 'spend') \\\n",
    "        .withColumn(\"timestamp\", lit(to_timestamp))\\\n",
    "        .collect()\n",
    "\n",
    "    write_rows_to_database(database.COLUMN_FAMILY_ID_LIST, df.collect())\n",
    "    write_rows_to_database(database.COLUMN_FAMILY_ID_BY_MINUTE, sum_by_minute_by_user_id)\n",
    "    write_rows_to_database(database.COLUMN_FAMILY_ID_BY_HOUR, sum_by_hour_by_user_id)\n",
    "    write_rows_to_database(database.COLUMN_FAMILY_ID_SUM, sum_by_user_id)\n",
    "\n",
    "def process(from_timestamp, to_timestamp):\n",
    "    _consume_subscription_queue(config.get_config()['pubsub']['subscription_id'])\n",
    "    _aggregate(from_timestamp, to_timestamp)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    to_timestamp = int(time.time())\n",
    "    from_timestamp = to_timestamp - 6 * 3600\n",
    "    _aggregate(from_timestamp, to_timestamp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
